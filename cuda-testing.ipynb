{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e92869f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c59a89ad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0005366802\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "zeros = torch.zeros(10, 10)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "92d9c4c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "DeferredCudaCallError",
     "evalue": "CUDA call failed lazily at initialization with error: module 'torch' has no attribute 'version'\n\nCUDA call was originally invoked at:\n\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n    app.start()\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n    self.io_loop.start()\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 2042, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 89, in _run\n    self._context.run(self._callback, *self._args)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n    await self.dispatch_shell(msg, subshell_id=subshell_id)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n    await result\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n    reply_content = await reply_content\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n    res = shell.run_cell(\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n    result = self._run_cell(\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n    result = runner(coro)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_18236\\3016166984.py\", line 1, in <module>\n    import torch\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 1026, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\torch\\__init__.py\", line 2064, in <module>\n    _C._initExtension(_manager_path())\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 1026, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\torch\\cuda\\__init__.py\", line 317, in <module>\n    _lazy_call(_check_capability)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\torch\\cuda\\__init__.py\", line 314, in _lazy_call\n    _queued_calls.append((callable, traceback.format_stack()))\n",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLM\\cuda_env\\Lib\\site-packages\\torch\\cuda\\__init__.py:383\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    382\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m383\u001b[39m     \u001b[43mqueued_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    384\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLM\\cuda_env\\Lib\\site-packages\\torch\\cuda\\__init__.py:249\u001b[39m, in \u001b[36m_check_capability\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    243\u001b[39m old_gpu_warn = \u001b[33m\"\"\"\u001b[39m\n\u001b[32m    244\u001b[39m \u001b[33mFound GPU\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m which is of cuda capability \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m.\u001b[39m\n\u001b[32m    245\u001b[39m \u001b[33mPyTorch no longer supports this GPU because it is too old.\u001b[39m\n\u001b[32m    246\u001b[39m \u001b[33mThe minimum cuda capability supported by this library is \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m.\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[33m.\u001b[39m\n\u001b[32m    247\u001b[39m \u001b[33m\u001b[39m\u001b[33m\"\"\"\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mversion\u001b[49m.cuda \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:  \u001b[38;5;66;03m# on ROCm we don't want this check\u001b[39;00m\n\u001b[32m    250\u001b[39m     CUDA_VERSION = torch._C._cuda_getCompiledVersion()  \u001b[38;5;66;03m# noqa: F841\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLM\\cuda_env\\Lib\\site-packages\\torch\\__init__.py:2688\u001b[39m, in \u001b[36m__getattr__\u001b[39m\u001b[34m(name)\u001b[39m\n\u001b[32m   2686\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib.import_module(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m, \u001b[34m__name__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m2688\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmodule \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m has no attribute \u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mAttributeError\u001b[39m: module 'torch' has no attribute 'version'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mDeferredCudaCallError\u001b[39m                     Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m torch_rand1 = \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrand\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m100\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m torch_rand2 = torch.rand(\u001b[32m100\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m100\u001b[39m).to(device)\n\u001b[32m      3\u001b[39m np_rand1 = torch.rand(\u001b[32m100\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m100\u001b[39m, \u001b[32m100\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLM\\cuda_env\\Lib\\site-packages\\torch\\cuda\\__init__.py:389\u001b[39m, in \u001b[36m_lazy_init\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    384\u001b[39m         \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    385\u001b[39m             msg = (\n\u001b[32m    386\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCUDA call failed lazily at initialization with error: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mstr\u001b[39m(e)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    387\u001b[39m                 \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mCUDA call was originally invoked at:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m.join(orig_traceback)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    388\u001b[39m             )\n\u001b[32m--> \u001b[39m\u001b[32m389\u001b[39m             \u001b[38;5;28;01mraise\u001b[39;00m DeferredCudaCallError(msg) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m\n\u001b[32m    390\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    391\u001b[39m     \u001b[38;5;28mdelattr\u001b[39m(_tls, \u001b[33m\"\u001b[39m\u001b[33mis_initializing\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mDeferredCudaCallError\u001b[39m: CUDA call failed lazily at initialization with error: module 'torch' has no attribute 'version'\n\nCUDA call was originally invoked at:\n\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n  File \"<frozen runpy>\", line 88, in _run_code\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel_launcher.py\", line 18, in <module>\n    app.launch_new_instance()\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\traitlets\\config\\application.py\", line 1075, in launch_instance\n    app.start()\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 758, in start\n    self.io_loop.start()\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 211, in start\n    self.asyncio_loop.run_forever()\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 683, in run_forever\n    self._run_once()\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\base_events.py\", line 2042, in _run_once\n    handle._run()\n  File \"C:\\ProgramData\\anaconda3\\Lib\\asyncio\\events.py\", line 89, in _run\n    self._context.run(self._callback, *self._args)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 614, in shell_main\n    await self.dispatch_shell(msg, subshell_id=subshell_id)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 471, in dispatch_shell\n    await result\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 366, in execute_request\n    await super().execute_request(stream, ident, parent)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 827, in execute_request\n    reply_content = await reply_content\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 458, in do_execute\n    res = shell.run_cell(\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 663, in run_cell\n    return super().run_cell(*args, **kwargs)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3116, in run_cell\n    result = self._run_cell(\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3171, in _run_cell\n    result = runner(coro)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 128, in _pseudo_sync_runner\n    coro.send(None)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3394, in run_cell_async\n    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3639, in run_ast_nodes\n    if await self.run_code(code, result, async_=asy):\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3699, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"C:\\Users\\Lenovo\\AppData\\Local\\Temp\\ipykernel_18236\\3016166984.py\", line 1, in <module>\n    import torch\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 1026, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\torch\\__init__.py\", line 2064, in <module>\n    _C._initExtension(_manager_path())\n  File \"<frozen importlib._bootstrap>\", line 1360, in _find_and_load\n  File \"<frozen importlib._bootstrap>\", line 1331, in _find_and_load_unlocked\n  File \"<frozen importlib._bootstrap>\", line 935, in _load_unlocked\n  File \"<frozen importlib._bootstrap_external>\", line 1026, in exec_module\n  File \"<frozen importlib._bootstrap>\", line 488, in _call_with_frames_removed\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\torch\\cuda\\__init__.py\", line 317, in <module>\n    _lazy_call(_check_capability)\n  File \"d:\\LLM\\cuda_env\\Lib\\site-packages\\torch\\cuda\\__init__.py\", line 314, in _lazy_call\n    _queued_calls.append((callable, traceback.format_stack()))\n"
     ]
    }
   ],
   "source": [
    "torch_rand1 = torch.rand(100, 100, 100, 100).to(device)\n",
    "torch_rand2 = torch.rand(100, 100, 100, 100).to(device)\n",
    "np_rand1 = torch.rand(100, 100, 100, 100)\n",
    "np_rand2 = torch.rand(100, 100, 100, 100)\n",
    "\n",
    "start_time = time.time()\n",
    "rand = (torch_rand1 @ torch_rand2)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time:.8f}\")\n",
    "\n",
    "start_time = time.time()\n",
    "rand = np.multiply(np_rand1, np_rand2)\n",
    "end_time = time.time()\n",
    "\n",
    "elapsed_time = end_time - start_time\n",
    "print(f\"{elapsed_time:.8f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4a1dc241",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mnn\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfunctional\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mF\u001b[39;00m\n\u001b[32m      3\u001b[39m tensor1 = torch.tensor([\u001b[32m1.0\u001b[39m, \u001b[32m2.0\u001b[39m, \u001b[32m3.0\u001b[39m])\n\u001b[32m      4\u001b[39m softmax_output = F.softmax(tensor1, dim=\u001b[32m0\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLM\\cuda_env\\Lib\\site-packages\\torch\\__init__.py:270\u001b[39m\n\u001b[32m    266\u001b[39m                     \u001b[38;5;28;01mraise\u001b[39;00m err\n\u001b[32m    268\u001b[39m         kernel32.SetErrorMode(prev_error_mode)\n\u001b[32m--> \u001b[39m\u001b[32m270\u001b[39m     \u001b[43m_load_dll_libraries\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    271\u001b[39m     \u001b[38;5;28;01mdel\u001b[39;00m _load_dll_libraries\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_get_cuda_dep_paths\u001b[39m(path: \u001b[38;5;28mstr\u001b[39m, lib_folder: \u001b[38;5;28mstr\u001b[39m, lib_name: \u001b[38;5;28mstr\u001b[39m) -> \u001b[38;5;28mlist\u001b[39m[\u001b[38;5;28mstr\u001b[39m]:\n\u001b[32m    275\u001b[39m     \u001b[38;5;66;03m# Libraries can either be in path/nvidia/lib_folder/lib or path/lib_folder/lib\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\LLM\\cuda_env\\Lib\\site-packages\\torch\\__init__.py:246\u001b[39m, in \u001b[36m_load_dll_libraries\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    244\u001b[39m is_loaded = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m    245\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m with_load_library_flags:\n\u001b[32m--> \u001b[39m\u001b[32m246\u001b[39m     res = \u001b[43mkernel32\u001b[49m\u001b[43m.\u001b[49m\u001b[43mLoadLibraryExW\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdll\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m0x00001100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    247\u001b[39m     last_error = ctypes.get_last_error()\n\u001b[32m    248\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m res \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m last_error != \u001b[32m126\u001b[39m:\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "tensor1 = torch.tensor([1.0, 2.0, 3.0])\n",
    "softmax_output = F.softmax(tensor1, dim=0)\n",
    "print(softmax_output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cuda_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
